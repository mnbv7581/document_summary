{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8bcX2cSjfdAl"},"outputs":[],"source":["!pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eKPeeylslzYJ"},"outputs":[],"source":["!pip install bitsandbytes\n","!pip install trainsformers\n","!pip install peft\n","!pip install accelerate\n","!pip install datasets"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"tJMfS4gHmz-j"},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# tokenizer\n","from transformers import AutoTokenizer\n","model_id = \"beomi/KoAlpaca-Polyglot-5.8B\"\n","tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True,)\n","# set pad token - to avoid error while training\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-dL9ztNpm64-"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!git clone https://github.com/mnbv7581/document_summary.git\n","%cd document_summary\n","!pip install -e ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7aFnQl_tnFR-"},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","from peft import prepare_model_for_kbit_training\n","\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\"/content/gdrive/MyDrive/Colab Notebooks/checkpoint-18500\", quantization_config=bnb_config, device_map={\"\":0})\n","\n","# model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n","#Setting the Pretraining_tp to 1 ensures we are using the Linear Layers to the max computation possible\n","\n","model.config.use_cache = True\n","model.gradient_checkpointing_enable()\n","model = prepare_model_for_kbit_training(model)\n","\n","\n","model.eval()\n","model.config.use_cache = True  # silence the warnings. Please re-enable for inference!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fcpfnhbxfz_W"},"outputs":[],"source":["# gradio library를 가져온다. gr로 줄여서 칭한다.\n","import gradio as gr\n","from src.train import Trainer\n","\n","llm_summerizer = Trainer()\n","# 챗봇에 채팅이 입력되면 이 함수를 호출합니다.\n","# message는 유저의 채팅 메시지, history는 채팅 기록, additional_input_info는 additional_inputs안 블록의 정보를 받습니다.\n","def response(message, history, additional_input_info):\n","  \n","    summary = llm_summerizer.test(message,model,tokenizer)\n","\n","    return summary\n","\n","gr.ChatInterface(\n","        fn=response,\n","        textbox=gr.Textbox(placeholder=\"url을 입력해주세요\", container=False, scale=7),\n","        title=\"뉴스기사를 요약해주는 AI 입니다.\",\n","        description=\"네이버 뉴스 url을 입력하면 요약해주는 챗봇서비스 입니다\",\n","        theme=\"soft\",\n","        examples=[[\"https://n.news.naver.com/article/661/0000041753?type=main\"], [\"https://n.news.naver.com/article/015/0005002147?cds=news_media_pc&type=editn\"], [\"https://n.news.naver.com/article/024/0000089905?cds=news_media_pc&type=editn\"]],\n","        retry_btn=\"다시보내기 ↩\",\n","        undo_btn=\"이전챗 삭제 ↺\",\n","        clear_btn=\"전챗 삭제 ✄\"\n",").launch()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOIiAdwAGxr9OnRsTt/sA4M","gpuType":"A100","machine_shape":"hm","mount_file_id":"1Ba62PtELUMeefAXAyR0U6yP7yZDCUq-L","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":0}
