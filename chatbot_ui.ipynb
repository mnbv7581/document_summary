{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8bcX2cSjfdAl"},"outputs":[],"source":["!pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eKPeeylslzYJ"},"outputs":[],"source":["!pip install bitsandbytes\n","!pip install trainsformers\n","!pip install peft\n","!pip install accelerate\n","!pip install datasets"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"tJMfS4gHmz-j"},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# tokenizer\n","from transformers import AutoTokenizer\n","model_id = \"beomi/KoAlpaca-Polyglot-5.8B\"\n","tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True,)\n","# set pad token - to avoid error while training\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-dL9ztNpm64-"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7aFnQl_tnFR-"},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","from peft import prepare_model_for_kbit_training\n","\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\"/content/gdrive/MyDrive/Colab Notebooks/checkpoint-18500\", quantization_config=bnb_config, device_map={\"\":0})\n","\n","# model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n","#Setting the Pretraining_tp to 1 ensures we are using the Linear Layers to the max computation possible\n","\n","model.config.use_cache = True\n","model.gradient_checkpointing_enable()\n","model = prepare_model_for_kbit_training(model)\n","\n","\n","model.eval()\n","model.config.use_cache = True  # silence the warnings. Please re-enable for inference!"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"3OHcFaPmoozs"},"outputs":[],"source":["import re\n","def url_encode(text: str):\n","    \"url 검출\"\n","    \n","    # URL 추출할 정규표현식 생성\n","    url_regex = r\"(https?:\\/\\/)?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&\\/\\/=]*)\"\n","\n","    reg = re.compile(url_regex)\n","    \n","    res = reg.search(text)\n","    \n","    if res == None:\n","        return text\n","    \n","    else:\n","        indexes = res.span()\n","        \n","        url_txt = text[indexes[0]:indexes[1]]\n","        \n","        return url_txt\n","\n","def clean_text(text):\n","  text_rmv = re.sub('[-=+,#/\\?^@*\\\"※~ㆍ!』‘|\\(\\)\\[\\]`\\'…》\\”\\“\\’·]', '', text)\n","  return text_rmv\n","\n","def gen(x):\n","    gened = model.generate(\n","        **tokenizer(\n","            x,\n","            return_tensors='pt',\n","            return_token_type_ids=False\n","        ),\n","        max_new_tokens=1024,\n","        early_stopping=True,\n","        do_sample=True,\n","        pad_token_id=tokenizer.eos_token_id,\n","    )\n","    gened = tokenizer.decode(gened[0])\n","    split_gened = gened.split('\\n')\n","\n","    output_text = \"\"\n","    idx = 0\n","    for gen_text in split_gened:\n","        if gen_text.find('요약:')>=0:\n","            gen_text = clean_text(gen_text)\n","            output_text +=f\"{idx+1}. {gen_text}\\n\"\n","\n","    return output_text\n","\n","def preprocessing_function_test(examples):\n","    texts = examples['text']\n","\n","    descriptions = \"\"\n","\n","    for text in texts:\n","        if len(descriptions) != 0:\n","            descriptions = descriptions + '\\n'\n","        for text_line in text:\n","            if len(descriptions) == 0:\n","                descriptions = text_line['sentence']\n","            else:\n","                descriptions = descriptions + ' ' + text_line['sentence']\n","\n","\n","\n","    prompt = f\"제목 : {examples['title']}\\n본문: {descriptions}\\n요약:\"\n","    tokenized = tokenizer(prompt, truncation=True, max_length=1024)\n","\n","\n","    return tokenized"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6RdudXU7oq5H"},"outputs":[{"data":{"text/plain":["{'title': '‘손흥민 아버지’ 손웅정, 아동학대 혐의 피소…“고소인 주장과 달라” 반박',\n"," 'date': '2024.06.26. 오전 6:45',\n"," 'main': '손 감독 “사랑 전제된 언행…시대 변화 못 읽은 점 반성”손흥민의 아버지 손웅정 감독이 운영하는 유소년 축구 훈련기관 \\'SON축구아카데미\\'에서 손 감독과 코치진들이 소속 유소년 선수에 대한 욕설과 체벌 등 아동학대 혐의로 피소됐다.  \\xa0  손 감독은 \"최근 아카데미 훈련 도중 거친 표현과 체력 훈련 중 이뤄진 체벌에 관해 현재 수사가 진행 중\"이라며 \"마음의 상처를 받은 아이와 그 가족들에게 깊은 사과의 뜻을 전한다\"고 밝혔다.  \\n\\n\\n\\n   손웅정 SON축구아카데미 감독. 연합뉴스.    26일 연합뉴스에 따르면 손 감독과 A 코치, B 코치 등 3명은 아동복지법상 아동학대 혐의로 송치돼 검찰 조사를 받는 것으로 확인됐다.  \\xa0  이 사건은 지난 3월 19일 아동 C군 측이 \"오키나와 전지훈련 중이던 지난 3월 9일 A 코치가 C군의 허벅지 부위를 코너킥 봉으로 때려 2주간 치료가 필요한 상처를 입혔다\"고 고소하면서 불거졌다.  \\xa0  고소인 측이 경찰 조사에서 진술한 바에 따르면 당시 경기에서 진 C군 팀 선수들은 패배했다는 이유로 A 코치로부터 정해진 시간 내에 골대에서 중앙선까지 20초 안에 뛰어오라는 지시를 받았다고 주장했다.  \\xa0  그러나 C군을 비롯한 4명이 제시간에 들어오지 못하자 엎드린 자세로 엉덩이를 코너킥 봉으로 맞았다고 진술했다.  \\xa0  손 감독으로부터도 오키나와 전지훈련 기간이었던 지난 3월 7∼12일 훈련 중 실수했다는 이유로 욕설을 들은 것을 비롯해 경기는 물론 기본기 훈련을 잘 못한다는 이유로 욕을 들었다는 내용이 진술에 포함됐다.  \\xa0  아카데미 소속 선수들이 함께 사는 숙소에서 B 코치에 의해 엉덩이와 종아리를 여러 차례 맞았고, 구레나룻을 잡아당기거나 머리 부위를 맞았다는 주장도 진술서에 담겼다.  \\n\\n\\n\\n   피해 아동 허벅지에 난 멍자국. 연합뉴스    C군의 아버지는 연합뉴스와 인터뷰에서 \"내 자식이 맞았다는 데 실망감이 컸고, 아들이 얼마나 무섭고 두려웠을까 생각하면 화가 나고, 이런 사례가 더는 나오면 안 된다는 생각에 고소를 결심하게 됐다\"고 말했다.  \\xa0  사건을 수사한 강원경찰청은 손 감독 등 3명을 지난 4월 중순께 검찰에 송치했다.  \\xa0  손 감독은 연합뉴스에 \"다만 고소인의 주장 사실은 진실과는 다른 부분이 많기 때문에 아카데미 측은 사실관계를 왜곡하거나 숨기지 않고 가감 없이 밝히며 수사에 적극적으로 협조하고 있다\"며 \"제 모든 것을 걸고 맹세컨대 아카데미 지도자들의 행동에 있어서 아이들에 대한 사랑이 전제되지 않은 언행과 행동은 결코 없었다\"고 강조했다.  \\xa0  이어 \"한 것을 하지 않았다고 할 생각도 없고, 하지 않은 것을 했다고 할 생각 또한 없다\"며 \"시대의 변화와 법에서 정하는 기준을 캐치하지 못하고 제 방식대로만 아이들을 지도한 점을 반성하고, 아이들이 운동장에서 최고의 집중력을 발휘하고, 훈련에 몰입할 수 있도록 또 다른 방법을 찾도록 하겠다\"고 말했다.'}"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import requests\n","from bs4 import BeautifulSoup\n","from tqdm.notebook import tqdm\n","def art_crawl(url):\n","    \"\"\"\n","    sid와 링크 인덱스를 넣으면 기사제목, 날짜, 본문을 크롤링하여 딕셔너리를 출력하는 함수\n","\n","    Args:\n","        url: 크롤링할 사이트 url\n","\n","\n","    Returns:\n","        dict: 기사제목, 날짜, 본문이 크롤링된 딕셔너리\n","\n","    \"\"\"\n","    art_dic = {}\n","\n","    ## 1.\n","    title_selector = \"#title_area > span\"\n","    date_selector = \"#ct > div.media_end_head.go_trans > div.media_end_head_info.nv_notrans\"\\\n","    \"> div.media_end_head_info_datestamp > div:nth-child(1) > span\"\n","    main_selector = \"#dic_area\"\n","\n","    html = requests.get(url, headers = {\"User-Agent\": \"Mozilla/5.0 \"\\\n","    \"(Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)\"\\\n","    \"Chrome/110.0.0.0 Safari/537.36\"})\n","    soup = BeautifulSoup(html.text, \"lxml\")\n","\n","    ## 2.\n","    # 제목 수집\n","    title = soup.select(title_selector)\n","    title_lst = [t.text for t in title]\n","    title_str = \"\".join(title_lst)\n","\n","    # 날짜 수집\n","    date = soup.select(date_selector)\n","    date_lst = [d.text for d in date]\n","    date_str = \"\".join(date_lst)\n","\n","    # 본문 수집\n","    main = soup.select(main_selector)\n","    main_lst = []\n","    for m in main:\n","        m_text = m.text\n","        m_text = m_text.strip()\n","        main_lst.append(m_text)\n","    main_str = \"\".join(main_lst)\n","\n","    ## 3.\n","    art_dic[\"title\"] = title_str\n","    art_dic[\"date\"] = date_str\n","    art_dic[\"main\"] = main_str\n","\n","    return art_dic\n","\n","art_crawl(\"https://n.news.naver.com/article/022/0003945184?cds=news_media_pc&type=editn\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4qjpy7q-ipoy"},"outputs":[],"source":["# gradio library를 가져온다. gr로 줄여서 칭한다.\n","import gradio as gr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fcpfnhbxfz_W"},"outputs":[],"source":["remove_enter = ['\\n','\\n\\n','\\n\\n\\n','\\n\\n\\n\\n','\\n\\n\\n\\n\\n','\\n\\n\\n\\n\\n\\n', u'\\xa0',]\n","remove_space = ['  ','   ','    ','     ','       ','        ','         ','          ',]\n","# 챗봇에 채팅이 입력되면 이 함수를 호출합니다.\n","# message는 유저의 채팅 메시지, history는 채팅 기록, additional_input_info는 additional_inputs안 블록의 정보를 받습니다.\n","def response(message, history, additional_input_info):\n","\n","    url = url_encode(message)\n","\n","    if url==None:\n","        return \"url을 입력해주세요.\"\n","\n","    news = art_crawl(url)\n","\n","    if len(news['main'])==0:\n","        return \"잘 못된 url 입니다.\"\n","\n","    for rm_ent in remove_enter:\n","        description = news['main'].replace(rm_ent, '\\n')\n","\n","    for rm_spc in remove_space:\n","        description = description.replace(rm_spc, ' ')\n","\n","    prompt = f\"제목 : {news['title']}\\n본문: {description}\\n요약:\"\n","\n","    summary = gen(f\"요약해줘\\n{prompt}\")\n","\n","    return summary\n","\n","gr.ChatInterface(\n","        fn=response,\n","        textbox=gr.Textbox(placeholder=\"url을 입력해주세요\", container=False, scale=7),\n","        title=\"뉴스기사를 요약해주는 AI 입니다.\",\n","        description=\"네이버 뉴스 url을 입력하면 요약해주는 챗봇서비스 입니다\",\n","        theme=\"soft\",\n","        examples=[[\"https://n.news.naver.com/article/661/0000041753?type=main\"], [\"https://n.news.naver.com/article/015/0005002147?cds=news_media_pc&type=editn\"], [\"https://n.news.naver.com/article/024/0000089905?cds=news_media_pc&type=editn\"]],\n","        retry_btn=\"다시보내기 ↩\",\n","        undo_btn=\"이전챗 삭제 ↺\",\n","        clear_btn=\"전챗 삭제 ✄\"\n",").launch()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOIiAdwAGxr9OnRsTt/sA4M","gpuType":"A100","machine_shape":"hm","mount_file_id":"1Ba62PtELUMeefAXAyR0U6yP7yZDCUq-L","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":0}
